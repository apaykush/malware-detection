import numpy as np
import pandas as pd
import os
from sklearn.model_selection import GridSearchCV
from pathlib import Path
from tqdm import tqdm
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

def insert_row(df, row):
    insert_loc = df.index.max()
    if pd.isna(insert_loc):
        df.loc[0] = row
    else:
        df.loc[insert_loc + 1] = row

def extract_features(folder_path, malware_class):
    column_names = list(range(256)) + ['entropy', 'class']
    df = pd.DataFrame(columns=column_names)
    files = Path(folder_path).rglob("*")
    for file in tqdm(files):
        if os.path.isdir(file):
            continue
        count = 0.0
        bytes_arr = [0] * 256
        with open(file, "rb") as f:
            text = f.read()
            count += len(text)
            for byte in text:
                bytes_arr[byte] += 1
        count -= bytes_arr[0]
        entropy = 0
        for i in range(256):
            bytes_arr[i] /= count
            if bytes_arr[i] and i > 0:
                entropy -= bytes_arr[i] * np.log2(bytes_arr[i])
        insert_row(df, bytes_arr + [entropy, malware_class])
    df.drop(columns=[0], inplace=True)
    return df

def byte_frequency(folder_path, include_zero=True):
    column_names = list(range(256))
    df = pd.DataFrame(columns=column_names)
    files = Path(folder_path).rglob("*")
    for file in tqdm(files):
        if os.path.isdir(file):
            continue
        count = 0.0
        bytes_arr = [0] * 256
        with open(file, "rb") as f:
            text = f.read()
            count += len(text)
            for byte in text:
                bytes_arr[byte] += 1
        insert_row(df, bytes_arr)
    if not include_zero:
        df.drop(columns=[0], inplace=True)
    return df

def compute_idf(word, df):
    return np.log2(len(df) / sum(df[word] > 0))

def extract_all_features_without_zero(folder_path, malware_class):
    column_names = list(range(256)) + ['entropy', 'class']
    df = pd.DataFrame(columns=column_names)
    files = Path(folder_path).rglob("*")
    names = []
    for file in tqdm(files):
        if os.path.isdir(file):
            continue
        count = 0.0
        bytes_arr = [0] * 256
        names.append(str(file))
        with open(file, "rb") as f:
            text = f.read()
            count += len(text)
            for byte in text:
                bytes_arr[byte] += 1
        count -= bytes_arr[0]
        entropy = 0
        for i in range(256):
            bytes_arr[i] /= count
            if bytes_arr[i] and i > 0:
                entropy -= bytes_arr[i] * np.log2(bytes_arr[i])
        insert_row(df, bytes_arr + [entropy, malware_class])
    df.drop(columns=[0], inplace=True)
    return df, names

def get_all_features():
    leg_features, names_leg = extract_all_features_without_zero(LEG_FOLDER, 0)
    virus_features, names_virus = extract_all_features_without_zero(VIRUS_FOLDER, 1)
    test_features, names_test = extract_all_features_without_zero(TEST_FOLDER, 2)
    
    X = pd.concat([leg_features, virus_features, test_features], ignore_index=True)
    names = [names_leg, names_virus, names_test]
    
    freq_df_leg = byte_frequency(LEG_FOLDER, include_zero=False)
    freq_df_virus = byte_frequency(VIRUS_FOLDER, include_zero=False)
    freq_df_test = byte_frequency(TEST_FOLDER, include_zero=False)
    freq_df = pd.concat([freq_df_leg, freq_df_virus, freq_df_test], ignore_index=True)
    
    poss_range = range(1, 256)
    column_names = list(poss_range)
    append_str = "tfidf"
    tfidf_columns = [append_str + str(sub) for sub in column_names]
    df = pd.DataFrame(columns=tfidf_columns)
    
    idf_list = [compute_idf(i, freq_df) for i in poss_range]
    
    for i in range(len(X)):
        tfidf_list = np.array(X.loc[i,])[:-2] * idf_list
        insert_row(df, tfidf_list)
    
    return pd.concat([X, df], axis=1), names

def process_data():
    print('Data processing... Please, wait')
    X_res, names = get_all_features()
    print('Data processing... DONE')
    
    X_test = X_res[X_res['class'] == 2]
    X_test.pop('class')
    X_train = X_res[(X_res['class'] == 0) | (X_res['class'] == 1)]
    y_train = X_train.pop('class')
    
    print('Selecting informative features... Please, wait')
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('model', Lasso())
    ])
    search = GridSearchCV(pipeline, {'model__alpha': np.arange(0.1, 10, 0.1)}, cv=5, scoring="neg_mean_squared_error")
    search.fit(X_train, y_train)
    
    coefficients = search.best_estimator_.named_steps['model'].coef_
    importance = np.abs(coefficients)
    
    print('Chosen features:', np.array(X_train.columns)[importance > 0])
    informative_features = np.array(X_train.columns)[importance > 0]
    X_train = X_train[informative_features]
    X_test = X_test[informative_features]
    print('Selection of informative features... DONE')
    
    report = f'Informative features: {informative_features}'
    
    print('Model training... Please, wait')
    model1 = LogisticRegression(C=10, penalty='l2')
    model2 = RandomForestClassifier(max_depth=7, max_features=4, n_estimators=4)
    model1.fit(X_train, y_train)
    model2.fit(X_train, y_train)
    print('Model training... DONE')
    
    predict1 = model1.predict_proba(X_test)
    predict2 = model2.predict_proba(X_test)
    
    report += '''\nReport contains:
File name
Probability of belonging to legitimate software class
Probability of belonging to malware class
Conclusion about class membership'''
    
    for i, (name, (prob0, prob1)) in enumerate(zip(names[2], predict1), start=1):
        ans = 'malware file' if prob1 >= 0.5 else 'legitimate file'
        report += f'\n{i}) {name}\n{prob0:.3f}, {prob1:.3f}\n{ans}'
    
    for i, (name, (prob0, prob1)) in enumerate(zip(names[2], predict2), start=1):
        ans = 'malware file' if prob1 >= 0.5 else 'legitimate file'
        report += f'\n{i}) {name}\n{prob0:.3f}, {prob1:.3f}\n{ans}'
    
    print(report)
    with open(os.path.join(REPORT_FOLDER, 'report.txt'), 'w') as f:
        f.write(report)
    print('Report saved in folder ' + REPORT_FOLDER)
