import pandas as pd
import numpy as np
import os
from pathlib import Path
from tqdm import tqdm
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from tensorflow.keras import layers, models, regularizers
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# Data Preprocessing Functions

def load_data(file_path):
    return pd.read_csv(file_path)

def clean_data(df):
    # Example cleaning steps
    df = df.dropna()
    df = df.drop_duplicates()
    return df

def scale_data(df):
    scaler = StandardScaler()
    scaled_df = scaler.fit_transform(df)
    return pd.DataFrame(scaled_df, columns=df.columns)

def preprocess_data(file_path):
    df = load_data(file_path)
    df = clean_data(df)
    df = scale_data(df)
    return df

# Model Creation Functions

def create_cnn_lstm_model(max_len, n_class, bidirectional=False):
    cnn_lstm_model = models.Sequential()
    cnn_lstm_model.add(layers.Conv1D(
        filters=30, kernel_size=7, strides=1,
        kernel_regularizer=regularizers.l2(0.01),
        activation='relu', input_shape=(max_len, 1)
    ))
    cnn_lstm_model.add(layers.MaxPool1D(5))
    cnn_lstm_model.add(layers.Conv1D(
        filters=50, kernel_size=7, strides=1,
        kernel_regularizer=regularizers.l2(0.01),
        activation='relu'
    ))
    cnn_lstm_model.add(layers.MaxPool1D(5))
    cnn_lstm_model.add(layers.Conv1D(
        filters=90, kernel_size=7, strides=1,
        kernel_regularizer=regularizers.l2(0.01),
        activation='relu'
    ))
    cnn_lstm_model.add(layers.MaxPool1D(5))
    
    if bidirectional:
        cnn_lstm_model.add(layers.Bidirectional(
            layers.LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)
        ))
    else:
        cnn_lstm_model.add(layers.LSTM(
            units=128, dropout=0.2, recurrent_dropout=0.2
        ))
    
    cnn_lstm_model.add(layers.Dense(n_class, activation='softmax'))
    cnn_lstm_model.compile(
        optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']
    )
    
    return cnn_lstm_model

def create_cnn_model(max_len, n_class):
    cnn_model = models.Sequential()
    cnn_model.add(layers.Conv1D(
        filters=30, kernel_size=7, strides=1,
        kernel_regularizer=regularizers.l2(0.01),
        activation='relu', input_shape=(max_len, 1)
    ))
    cnn_model.add(layers.MaxPool1D(5))
    cnn_model.add(layers.Conv1D(
        filters=50, kernel_size=7, strides=1,
        kernel_regularizer=regularizers.l2(0.01),
        activation='relu'
    ))
    cnn_model.add(layers.MaxPool1D(5))
    cnn_model.add(layers.Conv1D(
        filters=90, kernel_size=7, strides=1,
        kernel_regularizer=regularizers.l2(0.01),
        activation='relu'
    ))
    cnn_model.add(layers.MaxPool1D(5))
    
    cnn_model.add(layers.Flatten())
    cnn_model.add(layers.Dropout(0.2))
    cnn_model.add(layers.Dense(256, activation='relu'))
    cnn_model.add(layers.Dropout(0.3))
    cnn_model.add(layers.Dense(n_class, activation='softmax'))
    
    cnn_model.compile(
        optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']
    )
    
    return cnn_model

# Model Training Functions

def train_logistic_regression(X_train, y_train):
    model = LogisticRegression()
    model.fit(X_train, y_train)
    return model

def train_random_forest(X_train, y_train):
    model = RandomForestClassifier()
    model.fit(X_train, y_train)
    return model

def train_nn_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):
    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)
    return model, history

# Model Evaluation Functions

def evaluate_model(y_true, y_pred):
    print(classification_report(y_true, y_pred))
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

# Utility Functions

def save_model(model, file_path):
    joblib.dump(model, file_path)

def load_model(file_path):
    return joblib.load(file_path)

# Example Workflow

def main():
    # Preprocess data
    file_path = 'data.csv'
    df = preprocess_data(file_path)
    
    # Split data
    X = df.drop(columns='target')
    y = df['target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Train models
    logreg_model = train_logistic_regression(X_train, y_train)
    rf_model = train_random_forest(X_train, y_train)
    
    # Evaluate models
    logreg_pred = logreg_model.predict(X_test)
    rf_pred = rf_model.predict(X_test)
    
    print("Logistic Regression Evaluation:")
    evaluate_model(y_test, logreg_pred)
    
    print("Random Forest Evaluation:")
    evaluate_model(y_test, rf_pred)
    
    # Save models
    save_model(logreg_model, 'logreg_model.pkl')
    save_model(rf_model, 'rf_model.pkl')
    
    # Load and predict with saved model
    loaded_model = load_model('logreg_model.pkl')
    loaded_pred = loaded_model.predict(X_test)
    print("Loaded Model Evaluation:")
    evaluate_model(y_test, loaded_pred)

if __name__ == "__main__":
    main()
